{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPTOpenAIExperiments\n",
    "\n",
    "This is a repository to hold experiments with the OpenAI GPT-3 API. The goal is to create a chatbot that can hold a conversation with a human.\n",
    "\n",
    "## Data\n",
    "\n",
    "The data used for training is a collection of movie scripts from the Cornell Movie Dialogs Corpus. The scripts have been cleaned and formatted for easier use.\n",
    "\n",
    "## Training\n",
    "\n",
    "The model was trained using the OpenAI API with the following settings:\n",
    "\n",
    "- Engine: davinci\n",
    "- Temperature: 0.7\n",
    "\n",
    "## Results\n",
    "\n",
    "The chatbot is able to hold a coherent conversation with a human. However, it does struggle with understanding context and following the conversation if it goes off track. It also tends to repeat itself and generate generic responses.\n",
    "\n",
    "## Future Work\n",
    "\n",
    "There is still room for improvement in the chatbot's performance. Some ideas for future work include:\n",
    "\n",
    "- Fine-tuning the model with more data and adjusting the training parameters\n",
    "- Implementing a context tracker to better understand the conversation\n",
    "- Adding a response selection mechanism to prevent repetition and generate more diverse responses\n",
    "\n",
    "## License\n",
    "\n",
    "This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai_secret_manager\n",
    "\n",
    "assert \"openai\" in openai_secret_manager.get_services()\n",
    "secrets = openai_secret_manager.get_secrets(\"openai\")\n",
    "\n",
    "print(secrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = secrets[\"api_key\"]\n",
    "\n",
    "model_engine = \"davinci\"\n",
    "\n",
    "def generate_text(prompt):\n",
    "    completions = openai.Completion.create(engine=model_engine, prompt=prompt, max_tokens=1024, n=1,stop=None,temperature=0.7)\n",
    "    message = completions.choices[0].text\n",
    "    return message.strip()"
   ]
  },
